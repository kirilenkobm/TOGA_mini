{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code was written in 2018, quite a while ago."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from numpy import log10\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please fill this fields with your data\n",
    "# now the fields are filled with default human vs rat example\n",
    "\n",
    "# please look at example files content\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# reference genome annotation\n",
    "ref_annot = os.path.join(data_dir, \"ens_annot_example.bed\")\n",
    "\n",
    "# ehain features\n",
    "chain_feats = os.path.join(data_dir, \"features_example.txt\")\n",
    "\n",
    "# ensembl data for reference and query orthologs\n",
    "ens_data = os.path.join(data_dir, \"ensembl_rat_data_example.txt\")\n",
    "\n",
    "# save train to...\n",
    "train_path = os.path.join(data_dir, \"train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read chain featutes file\n",
    "df = pd.read_csv(chain_feats, header=0, sep=\"\\t\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get longest isoform of each gene, ignore orther\n",
    "gene_to_isoforms = defaultdict(list)\n",
    "isofotm_to_len = {}\n",
    "longest_isoforms = []\n",
    "gene_to_longest = {}\n",
    "longest_to_gene = {}\n",
    "\n",
    "f = open(ens_data, \"r\")\n",
    "for line in f:\n",
    "    line_data = line.split(\"\\t\")\n",
    "    gene = line_data[0]\n",
    "    trans = line_data[1].rstrip()\n",
    "    gene_to_isoforms[gene].append(trans)\n",
    "f.close()\n",
    "\n",
    "f = open(ref_annot, \"r\")\n",
    "for line in f:\n",
    "    line_data = line[:-1].split(\"\\t\")\n",
    "    trans = line_data[3]\n",
    "    block_sizes = line_data[10].split(\",\")\n",
    "    overall_CDS = sum(int(x) for x in block_sizes if x != \"\")\n",
    "    isofotm_to_len[trans] = overall_CDS\n",
    "f.close()\n",
    "\n",
    "for gene, isoforms in gene_to_isoforms.items():\n",
    "    isof_lens = [(i, isofotm_to_len.get(i)) for i in isoforms if isofotm_to_len.get(i)]\n",
    "    if len(isof_lens) == 0:\n",
    "        continue  # no isoforms with length?\n",
    "    isof_len_sort = sorted(isof_lens, key=lambda x: x[1], reverse=True)\n",
    "    longest = isof_len_sort[0][0]\n",
    "    longest_isoforms.append(longest)\n",
    "    gene_to_longest[gene] = longest\n",
    "    longest_to_gene[longest] = gene\n",
    "\n",
    "longest_isoforms = set(longest_isoforms)  # set to search faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset\n",
    "# delete non-longest isoforms\n",
    "df = df[df[\"gene\"].isin(longest_isoforms)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of genes classified by Ensembl as one2one\n",
    "# left only intersection with longest isoforms\n",
    "Ens_df = pd.read_csv(ens_data, header=0, sep=\"\\t\")\n",
    "Ens_o2o_df = Ens_df[Ens_df[\"Rat homology type\"] == \"ortholog_one2one\"]\n",
    "Ens_one2ones_trans = set(Ens_o2o_df[\"Transcript stable ID\"])\n",
    "Ens_o2o_longest = longest_isoforms.intersection(Ens_one2ones_trans)\n",
    "print(len(Ens_o2o_longest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting positive dataset, left only one-2-ones according the ensembl\n",
    "pos_1 = df[df[\"gene\"].isin(Ens_o2o_longest)]\n",
    "# remove small chains / chains that 100% are not orthologs or paralogs\n",
    "# and genes that covered by > 10 chains also\n",
    "pos_1 = pos_1[pos_1[\"gene_overs\"] <= 10]\n",
    "pos_1[\"ex_covered\"] = pos_1[\"exon_cover\"] / pos_1[\"ex_fract\"] * 100\n",
    "pos_1 = pos_1[pos_1[\"ex_covered\"] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left genes that are covered with only one chain -> 99% rock-solid orthologs\n",
    "gene_times = Counter(pos_1[\"gene\"])\n",
    "genes_once = set(k for k, v in gene_times.items() if v == 1)\n",
    "genes_mult = set(k for k, v in gene_times.items() if v > 1)\n",
    "pos_2 = pos_1[pos_1[\"gene\"].isin(genes_once)]\n",
    "pos_2.drop([\"ex_covered\"], axis=1)\n",
    "print(len(pos_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need genes with multiple chains of reasonable length\n",
    "# but still one-2-one according the ensembl\n",
    "neg_1 = pos_1[pos_1[\"gene\"].isin(genes_mult)]\n",
    "# get chains, remove the top chain\n",
    "gene_to_chains = defaultdict(list)\n",
    "for elem in zip(neg_1[\"gene\"], neg_1[\"chain\"]):\n",
    "    gene_to_chains[elem[0]].append(elem[1])\n",
    "\n",
    "orth_chains = []\n",
    "for gene, chains in gene_to_chains.items():\n",
    "    chains_s = sorted(chains)\n",
    "    orth_chains.append(chains_s[0])\n",
    "\n",
    "orth_chains = set(orth_chains)\n",
    "neg_2 = neg_1[~neg_1[\"chain\"].isin(orth_chains)]\n",
    "print(len(neg_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class labels + merge df and save it\n",
    "pos_2.insert(len(pos_2.columns), \"y\", 1)\n",
    "neg_2.insert(len(neg_2.columns), \"y\", 0)\n",
    "\n",
    "merged = pd.concat([pos_2, neg_2])\n",
    "print(len(merged))\n",
    "\n",
    "merged.to_csv(train_path, sep=\"\\t\", index=False)\n",
    "print(merged.columns)\n",
    "print(merged[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe build a couple of plots\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "feat = \"gl_exo\"  # green for positive, red for negative sets\n",
    "merged[merged[\"y\"] == 1][feat].hist(bins=100, alpha=0.5, color=\"green\")\n",
    "merged[merged[\"y\"] == 0][feat].hist(bins=100, alpha=0.5, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "merged[\"chain_len_log\"] = log10(merged[\"chain_len\"])\n",
    "feat = \"chain_len_log\"  # green for positive, red for negative sets\n",
    "merged[merged[\"y\"] == 1][feat].hist(bins=100, alpha=0.5, color=\"green\")\n",
    "merged[merged[\"y\"] == 0][feat].hist(bins=100, alpha=0.5, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "merged[\"synt_log\"] = log10(merged[\"synt\"])\n",
    "feat = \"synt_log\"  # green for positive, red for negative sets\n",
    "merged[merged[\"y\"] == 1][feat].hist(bins=100, alpha=0.5, color=\"green\")\n",
    "merged[merged[\"y\"] == 0][feat].hist(bins=100, alpha=0.5, color=\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
